import streamlit as st
from meilisearch import Client
import time
import requests

from openai import OpenAI


client = OpenAI(
    api_key="sk-139a40229c0e4bd58191a7a2f8c9c8f3",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

# åˆå§‹åŒ– Meilisearch å®¢æˆ·ç«¯ï¼ˆæ›¿æ¢ä¸ºä½ çš„å®é™…åœ°å€ï¼Œè‹¥æœ‰ Master Key éœ€æ·»åŠ ï¼‰
MEILI_URL = "http://10.8.130.32:7700"
api_key = "ff962c139a9c43142b122d00f8c99f1d"  # å¦‚æœæœ‰è®¾ç½® Master Keyï¼Œè¯·å–æ¶ˆæ³¨é‡Šå¹¶å¡«å†™
meili_client = Client(MEILI_URL, api_key)  # Client(MEILI_URL, "Key")



def get_embedding(query):
    url = "http://10.8.130.31:6008/api/v1/embedding"
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Bearer sk-proj-mimouse"
    }
    payload = {
        "texts": [query],
        "model": "bge-m3"
    }
    response = requests.post(url, headers=headers, json=payload)
    response.raise_for_status()
    data = response.json()
    # å–ç¬¬ä¸€ä¸ª embedding
    return data["data"][0]["embedding"]



def search_meilisearch_hybrid(query, knowledge_base, top_k, semantic_ratio):
    try:
        index = meili_client.index(knowledge_base)
        embedding = get_embedding(query)
        results = index.search(
            query,
            {
                "vector": embedding,
                "hybrid": {
                    "semanticRatio": semantic_ratio,
                    "embedder": "bge_m3"
                },
                "limit": top_k
            }
        )
        return results.get("hits", []), True
    except Exception as e:
        st.error(f"è¿æ¥ Meilisearch å¤±è´¥ï¼š{str(e)}")
        return [], False

def get_summary_qianwen(text):
    prompt = f"è¯·ç”¨ä¸­æ–‡å¯¹ä»¥ä¸‹å†…å®¹ç”Ÿæˆç®€æ˜æ‘˜è¦ï¼š\n{text}"
    try:
        response = client.chat.completions.create(
            model="qwen-plus",  # æˆ–ä½ å®é™…æ”¯æŒçš„æ¨¡å‹å
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æ‘˜è¦åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=128
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}"

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("æœç´¢è®¾ç½®")
    # çŸ¥è¯†åº“é€‰æ‹©ï¼ˆéœ€ä¸ Meilisearch ä¸­çš„ç´¢å¼•åä¸€è‡´ï¼‰
    knowledge_base = st.selectbox(
        "çŸ¥è¯†åº“", 
        ["broker_reports"],  # æ›¿æ¢ä¸ºå®é™…ç´¢å¼•å
        help="é€‰æ‹©è¦æœç´¢çš„çŸ¥è¯†åº“"
    )
    # è¯­ä¹‰ç³»æ•°æ»‘å—ï¼ˆå¯æ ¹æ®ä¸šåŠ¡é€»è¾‘ä¼ é€’ç»™ Meilisearchï¼‰
    semantic_ratio = st.slider(
        "SemanticRatio", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.5, 
        step=0.1,
        help="è°ƒæ•´è¯­ä¹‰åŒ¹é…æƒé‡"
    )
    # è¿”å›ç»“æœæ•°é‡
    top_k = st.number_input(
        "è¿”å›ç»“æœæ•°é‡(topK)", 
        min_value=1, 
        max_value=100, 
        value=10, 
        step=1,
        help="æ§åˆ¶æœç´¢ç»“æœæ¡æ•°"
    )
    
    # çŠ¶æ€æ˜¾ç¤ºï¼ˆæœç´¢ååŠ¨æ€æ›´æ–°ï¼‰
    st.markdown("---")
    st.markdown(f"### å½“å‰çŸ¥è¯†åº“ï¼š{knowledge_base}")
    search_time_placeholder = st.empty()  # æœç´¢è€—æ—¶
    result_count_placeholder = st.empty()  # ç»“æœæ•°é‡

# ä¸»ç•Œé¢å¸ƒå±€
st.markdown("## ğŸ” çŸ¥è¯†åº“æœç´¢")
search_query = st.text_input("è¯·è¾“å…¥æœç´¢å…³é”®è¯", value="AI", help="æ”¯æŒå…³é”®è¯ã€çŸ­è¯­æœç´¢")
search_btn = st.button("æœç´¢", type="primary")

# æœç´¢é€»è¾‘
if search_btn:
    start_time = time.time()
    
    # è°ƒç”¨ Meilisearch æœç´¢
    results, success = search_meilisearch_hybrid(search_query, knowledge_base, top_k, semantic_ratio)
    
    # è®¡ç®—è€—æ—¶
    end_time = time.time()
    duration_ms = (end_time - start_time) * 1000
    
    # æ›´æ–°ä¾§è¾¹æ çŠ¶æ€
    search_time_placeholder.markdown(f"### æœç´¢è€—æ—¶ï¼š{duration_ms:.2f} ms")
    result_count_placeholder.markdown(f"### è¿”å›ç»“æœæ•°ï¼š{len(results)} æ¡")
    
    # å±•ç¤ºæœç´¢ç»“æœ
    if success and results:
        for i, hit in enumerate(results, start=1):
            st.markdown(f"### {i}. {hit.get('title', 'æ— æ ‡é¢˜')}")
            st.write(f"ğŸ†” SHA256: {hit.get('_sha256', hit.get('file_sha256', 'æ— '))}")
            st.write(f"ğŸ‘¤ ä½œè€…: {hit.get('author', 'æ— ')}")
            st.write(f"ğŸ¢ æœºæ„: {hit.get('organization', 'æ— ')}")
            st.write(f"ğŸ“Š è¡Œä¸š: {hit.get('industry', 'æ— ')}")
            #st.write(f"ğŸ“ æ‘˜è¦: {hit.get('abstract', 'æ— ')}")
            st.write(f"ğŸ“… å‘å¸ƒæ—¶é—´: {hit.get('publish_time', 'æ— ')}")
            st.write(f"ğŸ”— æ¥æº: {hit.get('source', 'æ— ')}")
            #st.write(f"ğŸ“„ æ‘˜è¦: {hit.get('content', 'æ— ')}")
            content = hit.get('content', '') or hit.get('abstract', '')
            if content:
                with st.spinner("æ­£åœ¨ç”Ÿæˆæ‘˜è¦..."):
                    summary = get_summary_qianwen(content)
            else:
                summary = "æ— å†…å®¹"
            st.write(f"ğŸ“ åƒé—®æ‘˜è¦: {summary}")
            # å…³é”®è¯æ•°ç»„å¤„ç†
            keywords = hit.get('keyword', [])
            if isinstance(keywords, list):
                keywords = ', '.join(keywords)
            st.write(f"ğŸ”‘ å…³é”®è¯: {keywords if keywords else 'æ— '}")
            # PDF é“¾æ¥
            pdf_link = hit.get('pdf_link')
            if pdf_link:
                st.markdown(f"[ğŸ“ PDFé“¾æ¥]({pdf_link})")
            # æ–‡ä»¶ç›´é“¾
            file_url = hit.get('file_url')
            if file_url:
                st.markdown(f"[ğŸ“ æ–‡ä»¶ä¸‹è½½]({file_url})")
            st.divider()
    elif not results:
        st.info("æœªæ‰¾åˆ°åŒ¹é…ç»“æœï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯")



#streamlit run test.py