import re
import streamlit as st
from meilisearch import Client
import time
import requests
import json
import os
from openai import OpenAI

# åŠ è½½é…ç½®æ–‡ä»¶
def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = "config.json"
    if not os.path.exists(config_path):
        st.error(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼")
        st.stop()
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
        st.stop()

# åŠ è½½é…ç½®
config = load_config()

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆé€šä¹‰åƒé—®ï¼‰
client = OpenAI(
    api_key=config["openai"]["api_key"],
    base_url=config["openai"]["base_url"],
)

# åˆå§‹åŒ– Meilisearch å®¢æˆ·ç«¯
meili_client = Client(
    config["meilisearch"]["url"], 
    config["meilisearch"]["api_key"]
)



def get_embedding(query):
    """è·å–æ–‡æœ¬çš„å‘é‡åµŒå…¥è¡¨ç¤º"""
    url = config["embedding"]["url"]
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {config['embedding']['api_key']}"
    }
    payload = {
        "texts": [query],
        "model": config["embedding"]["model"]
    }
    response = requests.post(url, headers=headers, json=payload)
    response.raise_for_status()
    data = response.json()
    # å–ç¬¬ä¸€ä¸ª embedding
    return data["data"][0]["embedding"]



def search_meilisearch_hybrid(query, knowledge_base, top_k, semantic_ratio):
    """ä½¿ç”¨æ··åˆæœç´¢ï¼ˆå…³é”®è¯+è¯­ä¹‰ï¼‰åœ¨ Meilisearch ä¸­æœç´¢æ–‡æ¡£"""
    try:
        # è·å–æŒ‡å®šçŸ¥è¯†åº“çš„ç´¢å¼•
        index = meili_client.index(knowledge_base)
        # è·å–æŸ¥è¯¢æ–‡æœ¬çš„å‘é‡åµŒå…¥
        embedding = get_embedding(query)
        # æ‰§è¡Œæ··åˆæœç´¢
        results = index.search(
            query,
            {
                "vector": embedding,
                "hybrid": {
                    "semanticRatio": 1 - semantic_ratio,  # è¯­ä¹‰æœç´¢æƒé‡
                    "embedder": "bge_m3"  # åµŒå…¥æ¨¡å‹åç§°
                },
                "limit": top_k  # è¿”å›ç»“æœæ•°é‡é™åˆ¶
            }
        )
        return results.get("hits", []), True
    except Exception as e:
        st.error(f"è¿æ¥ Meilisearch å¤±è´¥ï¼š{str(e)}")
        return [], False

def get_summary_qianwen(text):
    """ä½¿ç”¨é€šä¹‰åƒé—®ç”Ÿæˆæ–‡æœ¬æ‘˜è¦"""
    prompt = f"è¯·ç”¨ä¸­æ–‡å¯¹ä»¥ä¸‹å†…å®¹ç”Ÿæˆç®€æ˜æ‘˜è¦,åªéœ€è¿”å›æ‘˜è¦ï¼Œåˆ«çš„ä»»ä½•è¯´æ˜éƒ½ä¸è¿”å›ï¼š\n{text}"
    try:
        response = client.chat.completions.create(
            model=config["openai"]["model"], 
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æ‘˜è¦åŠ©æ‰‹ï¼Œåªéœ€è¿”å›æ‘˜è¦ï¼Œåˆ«çš„ä»»ä½•è¯´æ˜éƒ½ä¸è¿”å›ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,  # æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§
            max_tokens=128    # é™åˆ¶ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}"
    
def get_keywords_qianwen(text):
    """ä½¿ç”¨é€šä¹‰åƒé—®ç”Ÿæˆæ–‡æœ¬å…³é”®è¯"""
    prompt = f"è¯·ç”¨ä¸­æ–‡å¯¹ä»¥ä¸‹å†…å®¹ç”Ÿæˆå…³é”®è¯,åªéœ€è¿”å›å…³é”®è¯ï¼Œåˆ«çš„ä»»ä½•è¯´æ˜éƒ½ä¸è¿”å›ï¼š\n{text}"
    try:
        response = client.chat.completions.create(
            model=config["openai"]["model"], 
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡å…³é”®è¯åŠ©æ‰‹ï¼Œåªä¼šè¿”å›å…³é”®è¯ï¼Œåˆ«çš„ä»»ä½•è¯´æ˜éƒ½ä¸è¿”å›ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,  # æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§
            max_tokens=128    # é™åˆ¶ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"å…³é”®è¯ç”Ÿæˆå¤±è´¥: {e}"




# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("æœç´¢è®¾ç½®")
    # çŸ¥è¯†åº“é€‰æ‹©ï¼ˆéœ€ä¸ Meilisearch ä¸­çš„ç´¢å¼•åä¸€è‡´ï¼‰
    knowledge_base = st.selectbox(
        "çŸ¥è¯†åº“", 
        [config["search"]["default_knowledge_base"]], 
        help="é€‰æ‹©è¦æœç´¢çš„çŸ¥è¯†åº“"
    )
    # è¯­ä¹‰ç³»æ•°æ»‘å—ï¼ˆæ§åˆ¶è¯­ä¹‰æœç´¢ä¸å…³é”®è¯æœç´¢çš„æƒé‡æ¯”ä¾‹ï¼‰
    semantic_ratio = st.slider(
        "SemanticRatio", 
        min_value=0.0, 
        max_value=1.0, 
        value=config["search"]["default_semantic_ratio"], 
        step=0.1,
        help="è°ƒæ•´è¯­ä¹‰åŒ¹é…æƒé‡ï¼Œ0ä¸ºçº¯å…³é”®è¯æœç´¢ï¼Œ1ä¸ºçº¯è¯­ä¹‰æœç´¢"
    )
    # è¿”å›ç»“æœæ•°é‡
    top_k = st.number_input(
        "è¿”å›ç»“æœæ•°é‡(topK)", 
        min_value=1, 
        max_value=config["search"]["max_top_k"], 
        value=config["search"]["default_top_k"], 
        step=1,
        help="æ§åˆ¶æœç´¢ç»“æœæ¡æ•°"
    )
    
    # çŠ¶æ€æ˜¾ç¤ºï¼ˆæœç´¢ååŠ¨æ€æ›´æ–°ï¼‰
    st.markdown("---")
    st.markdown(f"### å½“å‰çŸ¥è¯†åº“ï¼š{knowledge_base}")
    search_time_placeholder = st.empty()  # æœç´¢è€—æ—¶
    result_count_placeholder = st.empty()  # ç»“æœæ•°é‡

# ä¸»ç•Œé¢å¸ƒå±€
st.markdown("## ğŸ” çŸ¥è¯†åº“æœç´¢")
search_query = st.text_input("è¯·è¾“å…¥æœç´¢å…³é”®è¯", value="AI", help="æ”¯æŒå…³é”®è¯ã€çŸ­è¯­æœç´¢ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¿›è¡Œè¯­ä¹‰ç†è§£")
search_btn = st.button("æœç´¢", type="primary")

# æœç´¢é€»è¾‘
if search_btn:
    # è®°å½•æœç´¢å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # è°ƒç”¨ Meilisearch æ··åˆæœç´¢
    results, success = search_meilisearch_hybrid(search_query, knowledge_base, top_k, semantic_ratio)
    
    # è®¡ç®—æœç´¢è€—æ—¶
    end_time = time.time()
    duration_ms = (end_time - start_time) * 1000
    
    # æ›´æ–°ä¾§è¾¹æ çŠ¶æ€æ˜¾ç¤º
    search_time_placeholder.markdown(f"### æœç´¢è€—æ—¶ï¼š{duration_ms:.2f} ms")
    result_count_placeholder.markdown(f"### è¿”å›ç»“æœæ•°ï¼š{len(results)} æ¡")
    
    # å±•ç¤ºæœç´¢ç»“æœ
    if success and results:
        for i, hit in enumerate(results, start=1):
            # æ˜¾ç¤ºæ–‡æ¡£æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
            st.markdown(f"### {i}. {hit.get('title', 'æ— æ ‡é¢˜')}")
            st.write(f"ğŸ†” SHA256: {hit.get('_sha256', hit.get('file_sha256', 'æ— '))}")
            st.write(f"ğŸ‘¤ ä½œè€…: {hit.get('author', 'æ— ')}")
            st.write(f"ğŸ¢ æœºæ„: {hit.get('organization', 'æ— ')}")
            st.write(f"ğŸ“Š è¡Œä¸š: {hit.get('industry', 'æ— ')}")
            st.write(f"ğŸ“… å‘å¸ƒæ—¶é—´: {hit.get('publish_time', 'æ— ')}")
            st.write(f"ğŸ”— æ¥æº: {hit.get('source', 'æ— ')}")
            
            # è·å–æ–‡æ¡£å†…å®¹å¹¶ç”ŸæˆAIæ‘˜è¦å’Œå…³é”®è¯
            content = hit.get('content', '') or hit.get('abstract', '')
            if content:
                with st.spinner("æ­£åœ¨ç”Ÿæˆæ‘˜è¦å’Œå…³é”®è¯..."):
                    summary = get_summary_qianwen(content)
                    keywords = get_keywords_qianwen(content)
            else:
                summary = 'æ— å†…å®¹'
                keywords = 'æ— å…³é”®è¯'
            
            # æ˜¾ç¤ºAIç”Ÿæˆçš„æ‘˜è¦å’Œå…³é”®è¯ï¼ˆmarkdownæ ¼å¼éœ€è¦ä¸¤ä¸ªä»¥ä¸Šç©ºæ ¼+\næ‰èƒ½æ¢è¡Œï¼‰
            st.write(f"ğŸ“ åƒé—®æ‘˜è¦:  \n{summary}")
            st.write(f"ğŸ”‘ åƒé—®å…³é”®è¯:  \n{keywords}")
            
            # æ˜¾ç¤ºæ–‡æ¡£é“¾æ¥
            pdf_link = hit.get('pdf_link')
            if pdf_link:
                st.markdown(f"[ğŸ“ PDFé“¾æ¥]({pdf_link})")
            
            file_url = hit.get('file_url')
            if file_url:
                st.markdown(f"[ğŸ“ æ–‡ä»¶ä¸‹è½½]({file_url})")
            
            st.divider()  # åˆ†éš”çº¿
    elif not results:
        st.info("æœªæ‰¾åˆ°åŒ¹é…ç»“æœï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯")



# è¿è¡Œå‘½ä»¤: streamlit run ai.py
